# Проект для курса Deep Learning

# Описание задачи. Что вы решаете, какой формат данных, какой таргет, какая метрика?

Задача - Retrieval Dialog System. <br>
Суть задачи - сделать модель болталку (такой чатбот, с которым ты говоришь на житейские темы) с выбором ответа из пула кандидатов. Это значит, что ответ не генерится по слову, а выбирается подходящий ответ из придуманных заранее (или взятых из датасета).<br>
Датасет - диалоги из книжек на русском языке в формате (реплика 1, реплика 2, 0/1), где 0 или 1 определяет, является ли реплика 2 правильным ответом на реплику 1. Соотношение 0 и 1 классов - примерно 50/50. <br>
Метрика - R@1/10

# Краткий обзор вашей задачи. Как другие люди раньше решали ее?

В целом так же как описано в следующей части:

# Какой бейзлайн будет у вашей задачи, если бейзлайн возможно сделать?

Предложение делится на токены, токены заменяются на индексы. Массив индексов подается на вход энкодеру, энкодер переводит предложение в векторное пространство (делает эмбеддинг предложения). Таким образом получаются эмбеддинги реплики 1 и реплики 2. Далее они оба подаются на вход другой модели, которая рассчитывает косинусное расстояние между ними и определяет, является ли реплика 2 ответом на реплику 1. 

После обучения на вход подается реплика 1, для нее рассчитывается эмбеддинг. Затем в векторном пространстве ищется наиболее подходящий ответ для этой реплики по косинусному расстоянию с векторами ответов. 

# Отчет о проделанной работе: с какими трудностями вы столкнулись, что было легко/тяжело, что нового узнали. Каких результатов удалось достичь?

Сначала я попробовала воспользоваться готовым решением [AI Hub](https://aihub.cloud.google.com/u/0/p/products%2F558c8a34-563c-481c-baca-887e082794be). Я обучила его на своих данных из книжек, формат данных был (реплика, ответ). То есть таргетов 0/1 не было. В качестве контекста я указывала ответ. 

Результаты получились довольно хорошие: в вариантах ответа на заданную реплику прослеживалась одна тематика и в целом ответы были адекватные. На первом месте в выдаче реальный ответ из датасета оказался толко 42 раза, что может свидетельствовать об отсутствии переобучения. 

Далее я попыталась написать похожую штуку самостоятельно, но ничего не получилось. Я получала эмбеддинги вопроса и ответа, считала их скалярное произверение, пропускала через линейный слой и решала задачу классификации (является ли реплика 2 адекватным ответом на реплику 1). До "разговора" с сетью так и не дошло, т.к. не получилось заставить лосс падать. Это была самая большая трудность. На игрушечном датасете из рандомных чисел все работало как надо, но на предложениях все ломалось. У меня так и не получилось понять, в чем была проблема. 

В итоге нормальные результаты получились только на AI Hub.
